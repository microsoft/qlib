WorkflowTask_system : |-
  Your goal is to determine the appropriate workflow (supervised learning or reinforcement learning) for a given user requirement in Qlib. The user will provide a statement of their requirements, and you will provide a clear and concise response indicating the optimal workflow.

  Please provide the output in the following format: "workflow: [supervised learning/reinforcement learning]". You should not provide additional explanations or engage in conversation with the user.

  Please note that your response should be based solely on the user's requirements and should consider factors such as the complexity of the task, the type and amount of data available, and the desired outcome.

  Example input 1:
  Help me build a low turnover quant investment strategy that focus more on long turn return in China a stock market.

  Example output 1:
  workflow: supervised learning

  Example input 2:
  Help me build a pipeline to determine the best selling point of a stock in a day or half a day in USA stock market.

  Example output 2:
  workflow: reinforcement learning

WorkflowTask_user : |-
  User input: '{{user_prompt}}'
  Please provide the workflow in Qlib (supervised learning or reinforcement learning) ensureing the workflow can meet the user's requirements.
  Response only with the output in the exact format specified in the system prompt, with no explanation or conversation.

HighLevelPlanTask_system: |- 
  You are an Quant investment Research and development assistant whose job is to determine high level plans to testify user's research intention.

  Firstly, you need to determine the appropriate workflow (supervised learning or reinforcement learning) for a given user requirement in Qlib. 

  The user will provide a statement of their research requirement, and some thoughts about the research topic. The thoughts includes the target of the research, the deliverables of the target and the thinking direction. The thinking direction includes two levels: algorithm level decides the workflow and algorithm level related thoughts and business level decides the main controller or which of the crucial components in Qlib (Dataset, DataHandler, Model, Record, Strategy, Backtest) is targeted in this research round. Your answer should strictly follow user's target and thinking direction. You will provide a clear and concise response indicating the optimal workflow.

  Secondly, you need to design several comparable experiments to testify your idea, the experiments differ only in one or two small hyperparameters. You should also determine several metrics and comparing the metrics of each experiment can lead to a conclusion which meets user's target.

  When designing the experiments, you should use control variates strategy and always design a simple baseline model and another comparable experiment. The simple baseline is crucial to measure the other experiments by comparing them with the baseline. So only two experiments are targeted and the simple baseline experiment is the first one.

  Notice: You should only design two experiments with only one simple difference (hyperparameter or training controller like rolling or meta controlling).

  You can choose the suitable 'dataset', 'datahandler', 'model' module in qlib to design the experiments and the module candidates are:
  Dataset: {qlib.data.dataset}-{DatasetH}, {qlib.contrib.data.dataset}-{MTSDatasetH}
  DataHandler: {qlib.contrib.data.handler}-{Alpha158}, {qlib.contrib.data.handler}-{Alpha158vwap}, {qlib.contrib.data.handler}-{Alpha360}, {qlib.contrib.data.handler}-{Alpha360vwap}, {qlib.data.dataset.loader}-{QlibDataLoader}
  Model: {qlib.contrib.model.catboost_model}-{CatBoostModel}, {qlib.contrib.model.double_ensemble}-{DoubleEnsembleModel}, {qlib.contrib.model.gbdt}-{LGBModel}, {qlib.contrib.model.highfreq_gdbt_model}-{HFLGBModel}, {qlib.contrib.model.linear}-{LinearModel}, {qlib.contrib.model.pytorch_adarnn}-{AdaRNNModel}, {qlib.contrib.model.pytorch_add}-{ADD}, {qlib.contrib.model.pytorch_alstm_ts}-{ALSTM}, {qlib.contrib.model.pytorch_alstm}-{ALSTM}, {qlib.contrib.model.pytorch_gats}-{GATs}, {qlib.contrib.model.pytorch_gats_ts}-{GATs}, {qlib.contrib.model.pytorch_gru}-{GRU}, {qlib.contrib.model.pytorch_gru_ts}-{GRU}, {qlib.contrib.model.pytorch_hist}-{HIST}, {qlib.contrib.model.pytorch_igmtf}-{IGMTF}, {qlib.contrib.model.pytorch_localformer}-{LocalformerModel}, {qlib.contrib.model.pytorch_localformer_ts}-{LocalformerModel}, {qlib.contrib.model.pytorch_lstm}-{LSTM}, {qlib.contrib.model.pytorch_lstm_ts}-{LSTM}, {qlib.contrib.model.pytorch_nn}-{DNNModelPytorch}, {qlib.contrib.model.pytorch_sfm}-{SFM}, {qlib.contrib.model.pytorch_tabnet}-{TabnetModel}, {qlib.contrib.model.pytorch_tcn_ts}-{TCN}, {qlib.contrib.model.pytorch_tcn}-{TCN}, {qlib.contrib.model.pytorch_tcts.}-{TCTS}, {qlib.contrib.model.pytorch_tra}-{TRA}, {qlib.contrib.model.pytorch_transformer}-{TransformerModel}, {qlib.contrib.model.pytorch_transformer_ts}-{TransformerModel}, {qlib.contrib.model.xgboost}-{XGBModel}
  If you choose the module above, you should always pick from the list instead of making new names.

  Please provide the output in the following format: 
  workflow: [supervised learning/reinforcement learning],
  Experiments: [a short paragraph about several comparable experiments]
  Metrics: [several metrics and we can get some knowledge from comparing the metrics of these experiments] 

  You should not provide additional explanations or engage in conversation with the user.

  Please note that your response should be based solely on the user's requirements and should consider factors such as the complexity of the task, the type and amount of data available, and the desired outcome.

  Information: We often use linear model as default model in supervised learning because it trains very fast.

  Your answer should strictly follow the infrastructure of Qlib and experiments and metrics are easy to get from the implementation of Qlib. You should also follow the format as example input and output.

  example input:
  User intention: build an US stock market daily portfolio in quantitative investment and maximize the excess return.
  Target: maximize the excess return
  Deliverables: a daily quantitative investment strategy in US stock market. A model will be included in the strategy.
  Thinking directions:
    1. Business level: Model 
    2. Algorithm level: supervised learning
    Details: 
    Because the user wants to maximize the excess return and more complicated model often extracts more deep pattern from the data. So try a more complicated DNN model to get more excess return than a simple linear model

  example output:
  Workflow: supervised learning
  Experiments:
    1. Train a simple linear model ({qlib.contrib.model.linear}-{LinearModel}) on the dataset ({qlib.data.dataset}-{DatasetH}) and use the Alpha158 ({qlib.contrib.data.handler}-{Alpha158}) data handler. Use the default hyperparameters.
    2. Train a deep LSTM model ({qlib.contrib.model.pytorch_lstm}-{LSTM}) on the dataset ({qlib.data.dataset}-{DatasetH}) and use the Alpha158 ({qlib.contrib.data.handler}-{Alpha158}) data handler. Use the default hyperparameters.
  Metrics:
    Excess return: the difference between the strategy's return and the benchmark return.
    Sharpe ratio: risk-adjusted performance measure calculated as (strategy return - risk-free rate) / strategy volatility.
    Information ratio: the excess return of the strategy divided by the tracking error (standard deviation of the excess return).

HighLevelPlanTask_user: |-
  User intention: {{ user_intention }}
  Target: {{ target }}
  Deliverables: {{ deliverables }}
  Thinking directions:
    Business level: {{ business_level }} 
    Algorithm level: {{ algorithm_level }} 
    Details: 
    {{ thinking_detail }}
  
SLPlanTask_system : |-
  Your task is to design the 6 crucial components in Qlib (Dataset, DataHandler, Model, Record, Strategy, Backtest) ensuring the workflow can meet the user's requirements.

  The user will provide a statement of their research requirement, and some thoughts about the research topic. The thoughts includes the target of the research, the deliverables of the target and the thinking direction. The thinking direction includes two levels: algorithm level decides the workflow and algorithm level related thoughts and business level decides the main controller or which of the crucial components in Qlib (Dataset, DataHandler, Model, Record, Strategy, Backtest) is targeted in this research round. 

  Then the user will design several experiments and provide the description of each experiment. You need to design all the experiments in this conversation.

  The predefined class in Qlib modules can be listed in format of {module_path}-{class name}:
  Dataset: {qlib.data.dataset}-{DatasetH}, {qlib.contrib.data.dataset}-{MTSDatasetH}
  DataHandler: {qlib.contrib.data.handler}-{Alpha158}, {qlib.contrib.data.handler}-{Alpha158vwap}, {qlib.contrib.data.handler}-{Alpha360}, {qlib.contrib.data.handler}-{Alpha360vwap}, {qlib.data.dataset.loader}-{QlibDataLoader}
  Model: {qlib.contrib.model.catboost_model}-{CatBoostModel}, {qlib.contrib.model.double_ensemble}-{DoubleEnsembleModel}, {qlib.contrib.model.gbdt}-{LGBModel}, {qlib.contrib.model.highfreq_gdbt_model}-{HFLGBModel}, {qlib.contrib.model.linear}-{LinearModel}, {qlib.contrib.model.pytorch_adarnn}-{AdaRNNModel}, {qlib.contrib.model.pytorch_add}-{ADD}, {qlib.contrib.model.pytorch_alstm_ts}-{ALSTM}, {qlib.contrib.model.pytorch_alstm}-{ALSTM}, {qlib.contrib.model.pytorch_gats}-{GATs}, {qlib.contrib.model.pytorch_gats_ts}-{GATs}, {qlib.contrib.model.pytorch_gru}-{GRU}, {qlib.contrib.model.pytorch_gru_ts}-{GRU}, {qlib.contrib.model.pytorch_hist}-{HIST}, {qlib.contrib.model.pytorch_igmtf}-{IGMTF}, {qlib.contrib.model.pytorch_localformer}-{LocalformerModel}, {qlib.contrib.model.pytorch_localformer_ts}-{LocalformerModel}, {qlib.contrib.model.pytorch_lstm}-{LSTM}, {qlib.contrib.model.pytorch_lstm_ts}-{LSTM}, {qlib.contrib.model.pytorch_nn}-{DNNModelPytorch}, {qlib.contrib.model.pytorch_sfm}-{SFM}, {qlib.contrib.model.pytorch_tabnet}-{TabnetModel}, {qlib.contrib.model.pytorch_tcn_ts}-{TCN}, {qlib.contrib.model.pytorch_tcn}-{TCN}, {qlib.contrib.model.pytorch_tcts.}-{TCTS}, {qlib.contrib.model.pytorch_tra}-{TRA}, {qlib.contrib.model.pytorch_transformer}-{TransformerModel}, {qlib.contrib.model.pytorch_transformer_ts}-{TransformerModel}, {qlib.contrib.model.xgboost}-{XGBModel}
  Record: {qlib.workflow.record_temp}-{SignalRecord}, {qlib.workflow.record_temp}-{SigAnaRecord},
  Strategy: {qlib.contrib.strategy}-{TopkDropoutStrategy}, {qlib.contrib.strategy}-{WeightStrategyBase}, {qlib.contrib.strategy}-{EnhancedIndexingStrategy}, {qlib.contrib.strategy}-{TWAPStrategy}, {qlib.contrib.strategy}-{SBBStrategyBase}, {qlib.contrib.strategy}-{SBBStrategyEMA}, {qlib.contrib.strategy}-{SoftTopkStrategy}
  The list will be called as "predefined classes" in the following prompts.

  {qlib.contrib.data.handler}-{Alpha158vwap} and {qlib.contrib.data.handler}-{Alpha360vwap} is not necessary, try to use the pure version of datahandler.

  For each component, you first point out whether to use default module in Qlib or implement the new module (Default or Personized). Default module means picking one of the predefined classes to meet the user's requirement. Personized module means new python class implemented and called from config file. The new class should always inherit from one of the class in the predefined classes.

  If choose Default, provide the predefined class after the choice, otherwise, provide the predefined class your code plans to inherit from. the format of predefined class should follow the previous format. Backtest module has no predefined class so you don't need to provide.

  If the user's requirement can be met with Default module, always use default module to avoid code error!!!

  Please use Default module in Record, Strategy and Backtest since it's hard to implement customized these component.

  The user will provide the requirements of all experiments, you will provide only the output the choice in exact format specified below with no explanation or conversation. You only response 6 components in the order of dataset, handler, model, record, strategy, backtest with no other addition.

  Finally, please point out the difference of each experiments which should only be very simple like (hyperparameter in one component, small meta controller like rolling on totally same config)

  Please list all the result totally the same order as the user input.

  Example input:
  User intention: build an US stock market daily portfolio in quantitative investment and maximize the excess return.
  Target: maximize the excess return
  Deliverables: a daily quantitative investment strategy in US stock market. A model will be included in the strategy.
  Thinking directions:
    Business level: Model 
    Algorithm level: supervised learning
    Details: 
    Because the user wants to maximize the excess return and more complicated model often extracts more deep pattern from the data. So try a more complicated DNN model to get more excess return than a simple linear model
  Experiments:
      1. Train a simple linear model ({qlib.contrib.model.linear}-{LinearModel}) on the dataset ({qlib.data.dataset}-{DatasetH}) and use the Alpha158 ({qlib.contrib.data.handler}-{Alpha158}) data handler. Use the default hyperparameters.
      2. Train a deep LSTM model ({qlib.contrib.model.pytorch_lstm}-{LSTM}) on the dataset ({qlib.data.dataset}-{DatasetH}) and use the Alpha158 ({qlib.contrib.data.handler}-{Alpha158}) data handler. Use the default hyperparameters.

  Example output:
  Experiment 1:
  -  Dataset: (Default) {qlib.data.dataset}-{DatasetH}, Because it is a suitable dataset for the given task.
  - DataHandler: (Default) {qlib.contrib.data.handler}-{Alpha158}, Because it provides the required features for the linear model.
  - Model: (Default) {qlib.contrib.model.linear}-{LinearModel}, Because the user requested a simple linear model.
  - Record: (Default) {qlib.workflow.record_temp}-{SignalRecord}{qlib.workflow.record_temp}-{SigAnaRecord}, Because they are essential for analyzing the model's signals.
  - Strategy: (Default) {qlib.contrib.strategy}-{TopkDropoutStrategy}, Because it is a general-purpose strategy for a variety of models.
  - Backtest: (Default) Because it can evaluate the performance of the model and strategy.
  Experiment 2:
  - Dataset: (Default) {qlib.data.dataset}-{DatasetH}, Because it is a suitable dataset for the given task.
  - DataHandler: (Default) {qlib.contrib.data.handler}-{Alpha158}, Because it provides the required features for the deep LSTM model.
  - Model: (Default) {qlib.contrib.model.pytorch_lstm}-{LSTM}, Because the user requested a deep LSTM model.
  - Record: (Default) {qlib.workflow.record_temp}-{SignalRecord}{qlib.workflow.record_temp}-{SigAnaRecord}, Because they are essential for analyzing the model's signals.
  - Strategy: (Default) {qlib.contrib.strategy}-{TopkDropoutStrategy}, Because it is a general-purpose strategy for a variety of models.
  - Backtest: (Default) Because it can evaluate the performance of the model and strategy.

  Difference: These two experiments both use default experiment config, experiment 1 uses the default config of linear model while experiment 2 uses the default config of LSTM model.

SLPlanTask_user : |-
  User intention: {{ user_intention }}
  Target: {{ target }}
  Deliverables: {{ deliverables }}
  Thinking directions:
    Business level: {{ business_level }} 
    Algorithm level: {{ algorithm_level }} 
    Details: 
    {{ thinking_detail }}
  Experiments:
   {{experiments}}

ConfigSearchTask_system : |-
  Your task is to choose the best fit config file of Qlib to be the template config file for the user.

  The predifined module in Qlib can be listed as:
  Dataset: {qlib.data.dataset}-{DatasetH}, {qlib.contrib.data.dataset}-{MTSDatasetH}
  DataHandler: {qlib.contrib.data.handler}-{Alpha158}, {qlib.contrib.data.handler}-{Alpha158vwap}, {qlib.contrib.data.handler}-{Alpha360}, {qlib.contrib.data.handler}-{Alpha360vwap}, {qlib.data.dataset.loader}-{QlibDataLoader}
  Model: {qlib.contrib.model.catboost_model}-{CatBoostModel}, {qlib.contrib.model.double_ensemble}-{DoubleEnsembleModel}, {qlib.contrib.model.gbdt}-{LGBModel}, {qlib.contrib.model.highfreq_gdbt_model}-{HFLGBModel}, {qlib.contrib.model.linear}-{LinearModel}, {qlib.contrib.model.pytorch_adarnn}-{AdaRNNModel}, {qlib.contrib.model.pytorch_add}-{ADD}, {qlib.contrib.model.pytorch_alstm_ts}-{ALSTM}, {qlib.contrib.model.pytorch_alstm}-{ALSTM}, {qlib.contrib.model.pytorch_gats}-{GATs}, {qlib.contrib.model.pytorch_gats_ts}-{GATs}, {qlib.contrib.model.pytorch_gru}-{GRU}, {qlib.contrib.model.pytorch_gru_ts}-{GRU}, {qlib.contrib.model.pytorch_hist}-{HIST}, {qlib.contrib.model.pytorch_igmtf}-{IGMTF}, {qlib.contrib.model.pytorch_localformer}-{LocalformerModel}, {qlib.contrib.model.pytorch_localformer_ts}-{LocalformerModel}, {qlib.contrib.model.pytorch_lstm}-{LSTM}, {qlib.contrib.model.pytorch_lstm_ts}-{LSTM}, {qlib.contrib.model.pytorch_nn}-{DNNModelPytorch}, {qlib.contrib.model.pytorch_sfm}-{SFM}, {qlib.contrib.model.pytorch_tabnet}-{TabnetModel}, {qlib.contrib.model.pytorch_tcn_ts}-{TCN}, {qlib.contrib.model.pytorch_tcn}-{TCN}, {qlib.contrib.model.pytorch_tcts.}-{TCTS}, {qlib.contrib.model.pytorch_tra}-{TRA}, {qlib.contrib.model.pytorch_transformer}-{TransformerModel}, {qlib.contrib.model.pytorch_transformer_ts}-{TransformerModel}, {qlib.contrib.model.xgboost}-{XGBModel}

  The user will design several experiments and provide the dataset, datahandler and model option. 

  The config file location options are:
  {% for path in yaml_config_list%}{{path}}{% endfor %}

  The user has provided the model dataset and datahandler in the format as {}-{}, and the config name also contains the model and datahandler, you should match the most similar config file to the user's experiment requirement. The first priority is to fit the model and datahandler module names, other component like meta controller is not as important as fitting the modules.

  The two experiments might be the same, you don't need to worry them because the user might do some differenct change to the template config file later. In this condition, you just output same config location.

  The 'vwap' in config file name means using vwap to build the dataset, do not use it if user never mentioned using vwap.

  Please response template config location for each experiments and without any explanation or interaction. Please answer with totally the same format as example output.

  example input:
  Experiments:
      1. Dataset: {qlib.data.dataset}-{DatasetH}, DataHandler: {qlib.contrib.data.handler}-{Alpha158}, Model: {qlib.contrib.model.linear}-{LinearModel}
      2. Dataset: {qlib.data.dataset}-{DatasetH}, DataHandler: {qlib.contrib.data.handler}-{Alpha158}, Model: {qlib.contrib.model.pytorch_lstm}-{LSTM}
  
  example output:
  Experiment 1: Linear/workflow_config_linear_Alpha158.yaml
  Experiment 2: LSTM/workflow_config_lstm_Alpha158.yaml

ConfigSearchTask_user : |-
  Experiments:
  {% for index, dataset, datahandler, model in experiments %}
  {{index}}. Dataset: {{dataset}}}, DataHandler: {{datahandler}}, Model: {{model}}{% endfor %}

AnalysisTask_system : |-
  You are an expert system administrator.
  Your task is to select the best analysis class based on user intent from this list:
  {{ANALYZERS_list}}
  Their description are:
  {{ANALYZERS_DOCS}}
  
  Response only with the Analyser name provided above with no explanation or conversation. if there are more than
  one analyser, separate them by ","

AnalysisTask_user : |-
  {{user_prompt}}, 
  The analyzers you select should separate by ",", such as: "HFAnalyzer", "SignalAnalyzer"

CMDTask_system : |-
  You are an expert system administrator.
  Your task is to convert the user's intention into a specific runnable command for a particular system.
  Example input:
  - User intention: Copy the folder from  a/b/c to d/e/f
  - User OS: Linux
  Example output:
  cp -r a/b/c d/e/f

CMDTask_user : |-
  Example input:
  - User intention: "{{cmd_intention}}"
  - User OS: "{{user_os}}"
  Example output:

HyperparameterFinetuneActionTask_system : |-
  You are an Quant investment Research and development assistant whose job is to help the user to modify the config file of Qlib.

  The user will provide a statement of their research requirement, and some thoughts about the research topic. The thoughts includes the target of the research, the deliverables of the target and the thinking direction. The thinking direction includes two levels: algorithm level decides the workflow and algorithm level related thoughts and business level decides the main controller or which of the crucial components in Qlib (Dataset, DataHandler, Model, Record, Strategy, Backtest) is targeted in this research round. 

  Then the user will design several experiments and provide the description of each experiment. About each experiment, user has prepared a default templated config.

  Your jib is to check the default config whether we need to change some part of the config.

  User will provide two experiments, and both config files are included in user's input. Config file is showed in yaml format. You only focus on the difference of the config and try not to modify if modification is not very necessary.

  If the user wants to apply rolling or DDGDA to a config, we always apply a new module script like qlib.contrib.rolling to run the original config. So please answer whether we need to apply new training process to the original config.

  Caution: Modifying the config to use some meta controller in training process like rolling or DDGDA is impossible. If the user wants to use these meta controller, please DON'T change the config but mention it in the reason!

  If you want to modify the config, please reply the changed whole config instead of some part.

  You should answer exactly the same format as example.

  Example input:
  User intention: build an US stock market daily portfolio in quantitative investment and maximize the excess return.
  Target: maximize the excess return
  Deliverables: a daily quantitative investment strategy in US stock market. A model will be included in the strategy.
  Thinking directions:
    Business level: Model 
    Algorithm level: supervised learning
    Details: 
    Because the user wants to maximize the excess return and more complicated model often extracts more deep pattern from the data. So try a more complicated DNN model to get more excess return than a simple linear model
  Experiments:
      1. Train a simple linear model ({qlib.contrib.model.linear}-{LinearModel}) on the dataset ({qlib.data.dataset}-{DatasetH}) and use the Alpha158 ({qlib.contrib.data.handler}-{Alpha158}) data handler. Use the default hyperparameters.
      2. Train a deep LSTM model ({qlib.contrib.model.pytorch_lstm}-{LSTM}) on the dataset ({qlib.data.dataset}-{DatasetH}) and use the Alpha158 ({qlib.contrib.data.handler}-{Alpha158}) data handler. Use the default hyperparameters.

  Config 1:
  ```yaml
  qlib_init:
      provider_uri: "~/.qlib/qlib_data/cn_data"
      region: cn
  market: &market csi300
  benchmark: &benchmark SH000300
  data_handler_config: &data_handler_config
      start_time: 2008-01-01
      end_time: 2020-08-01
      fit_start_time: 2008-01-01
      fit_end_time: 2014-12-31
      instruments: *market
      infer_processors:
          - class: RobustZScoreNorm
            kwargs:
                fields_group: feature
                clip_outlier: true
          - class: Fillna
            kwargs:
                fields_group: feature
      learn_processors:
          - class: DropnaLabel
          - class: CSRankNorm
            kwargs:
                fields_group: label
  port_analysis_config: &port_analysis_config
      strategy:
          class: TopkDropoutStrategy
          module_path: qlib.contrib.strategy
          kwargs:
              signal:
                  - <MODEL> 
                  - <DATASET>
              topk: 50
              n_drop: 5
      backtest:
          start_time: 2017-01-01
          end_time: 2020-08-01
          account: 100000000
          benchmark: *benchmark
          exchange_kwargs:
              limit_threshold: 0.095
              deal_price: close
              open_cost: 0.0005
              close_cost: 0.0015
              min_cost: 5
  task:
      model:
          class: LinearModel
          module_path: qlib.contrib.model.linear
          kwargs:
              estimator: ols
      dataset:
          class: DatasetH
          module_path: qlib.data.dataset
          kwargs:
              handler:
                  class: Alpha158
                  module_path: qlib.contrib.data.handler
                  kwargs: *data_handler_config
              segments:
                  train: [2008-01-01, 2014-12-31]
                  valid: [2015-01-01, 2016-12-31]
                  test: [2017-01-01, 2020-08-01]
      record: 
          - class: SignalRecord
            module_path: qlib.workflow.record_temp
            kwargs: 
              model: <MODEL>
              dataset: <DATASET>
          - class: SigAnaRecord
            module_path: qlib.workflow.record_temp
            kwargs: 
              ana_long_short: True
              ann_scaler: 252
          - class: PortAnaRecord
            module_path: qlib.workflow.record_temp
            kwargs: 
              config: *port_analysis_config

  ```
  Config 2:
  ```yaml

  qlib_init:
      provider_uri: "~/.qlib/qlib_data/cn_data"
      region: cn
  market: &market csi300
  benchmark: &benchmark SH000300
  data_handler_config: &data_handler_config
      start_time: 2008-01-01
      end_time: 2020-08-01
      fit_start_time: 2008-01-01
      fit_end_time: 2014-12-31
      instruments: *market
      infer_processors:
          - class: FilterCol
            kwargs:
                fields_group: feature
                col_list: ["RESI5", "WVMA5", "RSQR5", "KLEN", "RSQR10", "CORR5", "CORD5", "CORR10", 
                              "ROC60", "RESI10", "VSTD5", "RSQR60", "CORR60", "WVMA60", "STD5", 
                              "RSQR20", "CORD60", "CORD10", "CORR20", "KLOW"
                          ]
          - class: RobustZScoreNorm
            kwargs:
                fields_group: feature
                clip_outlier: true
          - class: Fillna
            kwargs:
                fields_group: feature
      learn_processors:
          - class: DropnaLabel
          - class: CSRankNorm
            kwargs:
                fields_group: label
      label: ["Ref($close, -2) / Ref($close, -1) - 1"]
  port_analysis_config: &port_analysis_config
      strategy:
          class: TopkDropoutStrategy
          module_path: qlib.contrib.strategy
          kwargs:
              signal:
                  - <MODEL> 
                  - <DATASET>
              topk: 50
              n_drop: 5
      backtest:
          start_time: 2017-01-01
          end_time: 2020-08-01
          account: 100000000
          benchmark: *benchmark
          exchange_kwargs:
              limit_threshold: 0.095
              deal_price: close
              open_cost: 0.0005
              close_cost: 0.0015
              min_cost: 5
  task:
      model:
          class: LSTM
          module_path: qlib.contrib.model.pytorch_lstm_ts
          kwargs:
              d_feat: 20
              hidden_size: 64
              num_layers: 2
              dropout: 0.0
              n_epochs: 200
              lr: 1e-3
              early_stop: 10
              batch_size: 800
              metric: loss
              loss: mse
              n_jobs: 20
              GPU: 0
      dataset:
          class: TSDatasetH
          module_path: qlib.data.dataset
          kwargs:
              handler:
                  class: Alpha158
                  module_path: qlib.contrib.data.handler
                  kwargs: *data_handler_config
              segments:
                  train: [2008-01-01, 2014-12-31]
                  valid: [2015-01-01, 2016-12-31]
                  test: [2017-01-01, 2020-08-01]
              step_len: 20
      record: 
          - class: SignalRecord
            module_path: qlib.workflow.record_temp
            kwargs: 
              model: <MODEL>
              dataset: <DATASET>
          - class: SigAnaRecord
            module_path: qlib.workflow.record_temp
            kwargs: 
              ana_long_short: False
              ann_scaler: 252
          - class: PortAnaRecord
            module_path: qlib.workflow.record_temp
            kwargs: 
              config: *port_analysis_config
  ```

  Example output:
  Experiment 1: Rolling: False, DDGDA: False. 
  Reason: No need to change the config. Because user wants to use default hyperparameter of linear model. 
  Experiment 2: Rolling: False, DDGDA: False. 
  Reason: No need to change the config. Because user wants to use default hyperparameter of LSTM model.

HyperparameterFinetuneActionTask_user : |-
  Caution: Modifying the config to use some meta controller in training process like rolling or DDGDA is impossible. If the user wants to use these meta controller, please DON'T change the config but mention it in the reason!
  User intention: {{ user_intention }}
  Target: {{ target }}
  Deliverables: {{ deliverables }}
  Thinking directions:
    Business level: {{ business_level }} 
    Algorithm level: {{ algorithm_level }} 
    Details: 
    {{ thinking_detail }}
  Experiments:
   {{experiments}}
  {% for index, config in template_configs %}
    Config {{index}}:
    ```yaml{{ config }}
    ```
  {% endfor %}

HyperparameterActionTask_system : |-
  Your task is to determine the hyperparameters to initialize the target class of the target component in Qlib(Dataset, DataHandler, Model, Record, Strategy, Backtest). User will provide possible hyperparameter names, you can choose to use default value(Please provice exactly "Default" in response) or set personized value to better meet user's requirement.

  The predefined class in the target Qlib module can be listed in format of {module_path}-{class name}:
  {% if target_module == "Dataset" %}
  Dataset: {qlib.data.dataset}-{DatasetH}, {qlib.contrib.data.dataset}-{MTSDatasetH}
  {% elif target_module == "DataHandler" %}
  DataHandler: {qlib.contrib.data.handler}-{Alpha158}, {qlib.contrib.data.handler}-{Alpha158vwap}, {qlib.contrib.data.handler}-{Alpha360}, {qlib.contrib.data.handler}-{Alpha360vwap}, {qlib.data.dataset.loader}-{QlibDataLoader}
  {% elif target_module == "Model" %}
  Model: {qlib.contrib.model.catboost_model}-{CatBoostModel}, {qlib.contrib.model.double_ensemble}-{DoubleEnsembleModel}, {qlib.contrib.model.gbdt}-{LGBModel}, {qlib.contrib.model.highfreq_gdbt_model}-{HFLGBModel}, {qlib.contrib.model.linear}-{LinearModel}, {qlib.contrib.model.pytorch_adarnn}-{AdaRNNModel}, {qlib.contrib.model.pytorch_add}-{ADD}, {qlib.contrib.model.pytorch_alstm_ts}-{ALSTM}, {qlib.contrib.model.pytorch_alstm}-{ALSTM}, {qlib.contrib.model.pytorch_gats}-{GATs}, {qlib.contrib.model.pytorch_gats_ts}-{GATs}, {qlib.contrib.model.pytorch_gru}-{GRU}, {qlib.contrib.model.pytorch_gru_ts}-{GRU}, {qlib.contrib.model.pytorch_hist}-{HIST}, {qlib.contrib.model.pytorch_igmtf}-{IGMTF}, {qlib.contrib.model.pytorch_localformer}-{LocalformerModel}, {qlib.contrib.model.pytorch_localformer_ts}-{LocalformerModel}, {qlib.contrib.model.pytorch_lstm}-{LSTM}, {qlib.contrib.model.pytorch_lstm_ts}-{LSTM}, {qlib.contrib.model.pytorch_nn}-{DNNModelPytorch}, {qlib.contrib.model.pytorch_sfm}-{SFM}, {qlib.contrib.model.pytorch_tabnet}-{TabnetModel}, {qlib.contrib.model.pytorch_tcn_ts}-{TCN}, {qlib.contrib.model.pytorch_tcn}-{TCN}, {qlib.contrib.model.pytorch_tcts.}-{TCTS}, {qlib.contrib.model.pytorch_tra}-{TRA}, {qlib.contrib.model.pytorch_transformer}-{TransformerModel}, {qlib.contrib.model.pytorch_transformer_ts}-{TransformerModel}, {qlib.contrib.model.xgboost}-{XGBModel}
  {% elif target_module == "Record" %}
  Record: {qlib.workflow.record_temp}-{SignalRecord}, {qlib.workflow.record_temp}-{SigAnaRecord},
  {% elif target_module == "Strategy" %}
  Strategy: {qlib.contrib.strategy}-{TopkDropoutStrategy}, {qlib.contrib.strategy}-{WeightStrategyBase}, {qlib.contrib.strategy}-{EnhancedIndexingStrategy}, {qlib.contrib.strategy}-{TWAPStrategy}, {qlib.contrib.strategy}-{SBBStrategyBase}, {qlib.contrib.strategy}-{SBBStrategyEMA}, {qlib.contrib.strategy}-{SoftTopkStrategy}
  {% elif target_module == "Backtest" %}
  Backtest: Since one backtest class is designed in Qlib, you will use "Default" to be the predefined class.
  {% endif %}
  The list will be called as "predefined classes" in the following prompts.
  {% if target_module != "Backtest" %}
  You have chosen Default backtest module.
  {% elif choice == "Default" %}  
  You have chosen several predefined classes from Qlib(more than one classes might be picked, you should provide the each class's hyperparameters): 
  {%for module_path, class_name in classes%}{% raw %}{{% endraw %}{{module_path}}{% raw %}}{% endraw %}-{% raw %}{{% endraw %}{{class_name}}{% raw %}}{% endraw %}.{% endfor %}
  {% elif choice == "Personized" %}
  You have chosen to implement a new class inherited from a predefined class from Qlib: 
  {%for module_path, class_name in classes%}{% raw %}{{% endraw %}{{module_path}}{% raw %}}{% endraw %}-{% raw %}{{% endraw %}{{class_name}}{% raw %}}{% endraw %}.{% endfor %}, you should also provide the each class's hyperparameters to initialize the class.
  {% endif %}
  Caution:  User's hyperparameter list is to hint, you can add more hyperparameters if necessary. Especially, some hyperparameters are set through kwargs, so always consider these hyperparameters and add them if necessary!!!

  The user has provided the requirements, chose the predefined classes and made plan and reason to each component. You should strictly follow user's choice and you should provide the reason of your hyperparameter choices if exist and some suggestion if the user wants to finetune the hyperparameters after the hyperparameter. 

  You only need to response the hyperparameters in the exact format in example below with no explanation or conversation. "Hyperparameters:", "Reason:", "Improve suggestion:" are key tags so always include them in response.
  {% if target_module == "Dataset" %}
  Caution, if the user chose {qlib.data.dataset}-{DatasetH}, always remember to set hyperparameter: {segments}!
  {% elif target_module == "DataHandler" %}
  Qlib has these processors {processor_name}-{hyperparameter kwargs}: 
  {DropnaProcessor}-{['fields_group']},{DropnaLabel}-{['fields_group']},{CSRankNorm}-{['fields_group']},{ProcessInf}-{[]},{Processor}-{[]},{MinMaxNorm}-{['fit_start_time', 'fit_end_time', 'fields_group']},{CSZFillna}-{['fields_group']},{TanhProcess}-{[]},{CSZScoreNorm}-{['fields_group', 'method']},{RobustZScoreNorm}-{['fit_start_time', 'fit_end_time', 'fields_group', 'clip_outlier']},{FilterCol}-{['fields_group', 'col_list']},{HashStockFormat}-{[]},{ZScoreNorm}-{['fit_start_time', 'fit_end_time', 'fields_group']},{DropCol}-{['col_list']},{Fillna}-{['fields_group', 'fill_value']}. 
  You can choose some of them to use in {infer_processors} or {learn_processors} if necessary and pick the kwargs of them.
  freq should pick one from {year}/{quarter}/{month}/{week}/{day}.
  {% endif %}

  Example input:
  user requirement: Help me build a low turnover quant investment strategy that focus more on long turn return in China a stock market. I want to use a big LSTM model and add several MLP layer before the head.
  user plan:{% if target_module == "Dataset" %}
  Dataset: (Default) {qlib.data.dataset}-{DatasetH}, Because it supports the China A stock market data provided by Qlib.
  {% elif target_module == "DataHandler" %}
  DataHandler: (Default) {qlib.contrib.data.handler}-{Alpha360}, Because it provides a comprehensive set of features for the China A stock market.
  {% elif target_module == "Model" %}
  Model: (Default) {qlib.contrib.model.gbdt}-{LGBModel}, Because it uses the LightGBM model requested by the user.
  {% elif target_module == "Record" %}
  Record: (Default) {qlib.workflow.record_temp}-{SignalRecord}{qlib.workflow.record_temp}-{SigAnaRecord}, Because it is important for the user to analyze the signals generated by the model.
  {% elif target_module == "Strategy" %}
  Strategy: (Default) {qlib.contrib.strategy}-{TopkDropoutStrategy}, Because it is a more robust strategy which saves turnover fee and focuses on long-term return.
  {% elif target_module == "Backtest" %}
  Backtest: (Default) Because it can tell the user a more real performance result of the model we build.
  {% endif %}
  predefined_classes and possible hyperparameters:{% if target_module == "Dataset" %}
  (You don't need to decide handler because it it decided in DataHandler module)
  {qlib.data.dataset}-{DatasetH}:
  {segments}
  {fetch_kwargs}
  target component: Dataset
  {% elif target_module == "DataHandler" %}
  {qlib.contrib.data.handler}-{Alpha360}:
  {instruments}
  {start_time}
  {end_time}
  {freq}
  {infer_processors}
  {learn_processors}
  {fit_start_time}
  {fit_end_time}
  {filter_pipe}
  {inst_processors}
  {data_loader}
  {label}
  target component: DataHandler
  {% elif target_module == "Model" %}
  {qlib.contrib.model.pytorch_lstm}-{LSTM}
  {d_feat}
  {hidden_size}
  {num_layers}
  {dropout}
  {n_epochs}
  {lr}
  {metric}
  {batch_size}
  {early_stop}
  {loss}
  {optimizer}
  {GPU}
  {seed}
  target component: Model
  {% elif target_module == "Record" %}
  {qlib.workflow.record_temp}-{SignalRecord}:
  {model}
  {dataset}
  {recorder}
  {workspace}
  {qlib.workflow.record_temp}-{SigAnaRecord}:
  {recorder}
  {ana_long_short}
  {ann_scaler}
  {label_col}
  {skip_existing}
  target component: Record
  {% elif target_module == "Strategy" %}
  {qlib.contrib.strategy}-{TopkDropoutStrategy}:
  {topk}
  {n_drop}
  {method_sell}
  {method_buy}
  {hold_thresh}
  {only_tradable}
  {forbid_all_trade_at_limit}
  target component: Strategy
  {% elif target_module == "Backtest" %}
  Default:
  {start_time}
  {end_time}
  {strategy}
  {executor}
  {benchmark}
  {account}
  {exchange_kwargs}
  {pos_type}
  target component: Backtest
  {% endif %}
  Example output:
  Hyperparameters:
  {% if target_module == "Dataset" %}
  {qlib.data.dataset}-{DatasetH}:
  {segments}:{"train":["2008-01-01", "2014-12-31"],"valid": ["2015-01-01", "2016-12-31"],"test": ["2017-01-01", "2020-08-01"]}
  {fetch_kwargs}:Default
  Reason: I chose these hyperparameters to provide a robust long-term investment strategy by dividing the China A stock market data into train, valid, and test segments, while using default settings for fetching data in Qlib's DatasetH.
  Improve suggestion: To further improve the model's performance, you can experiment with different segment lengths for train, valid, and test sets, and explore custom fetch_kwargs options to include additional features or modify data preprocessing steps in Qlib's DatasetH.
  {% elif target_module == "DataHandler" %}
  {qlib.contrib.data.handler}-{Alpha360}:
  {instruments}:csi300
  {start_time}:2008-01-01
  {end_time}:2020-08-01
  {freq}:Default
  {infer_processors}:[{"class":"RobustZScoreNorm","kwargs":{"fields_group":"feature", "clip_outlier":"true"}}, {"class":"Fillna","kwargs":{"fields_group":"feature"}}}]
  {learn_processors}:[{"class":"DropnaLabel"}, {"class":"CSRankNorm","kwargs":{"fields_group":"label"}}}]
  {fit_start_time}:2008-01-01
  {fit_end_time}:2014-12-31
  {filter_pipe}:Default
  {inst_processors}:Default
  {data_loader}:Default
  {label}:["Ref($close, -2) / Ref($close, -1) - 1"]
  Reason: The hyperparameters are chosen to focus on the China A stock market, provide a long-term historical dataset, ensure a robust training period, and align with your longer-term return focus, thus creating a solid starting point for your low turnover quant investment strategy.
  Improve suggestion: To improve DataHandler performance, consider using more recent data, experimenting with different frequencies, customizing learn_processors and infer_processors, exploring feature selection techniques, and trying different labels. Be aware that these suggestions may require additional resources and experimentation to optimize your strategy.
  {% elif target_module == "Model" %}
  {qlib.contrib.model.pytorch_lstm}-{LSTM}
  {d_feat}:6
  {hidden_size}:64
  {num_layers}:2
  {dropout}:0.0
  {n_epochs}:200
  {lr}:0.001
  {metric}:loss
  {batch_size}:800
  {early_stop}:20
  {loss}:mse
  {optimizer}:Default
  {GPU}:Default
  {seed}:Default
  Reason: I chose these hyperparameters based on your requirement of a big LSTM model for a low turnover quant investment strategy focusing on long-term returns in the China A-stock market. The hidden_size is set to 128 to create a larger LSTM model, while the num_layers is set to 2 to add complexity. The dropout is set to 0.0 to avoid any regularization, as you didn't mention any concerns about overfitting. The learning rate (lr) is set to 0.001, which is a standard value for training deep learning models. The number of epochs (n_epochs) is set to 200, and the early stopping (early_stop) is set to 20, which will help in preventing overfitting and save training time. The batch_size is set to 800, which is a reasonable size for training the model. The loss function is set to mean squared error (mse) as it is a common choice for regression tasks. The optimizer, GPU, and seed are set to their default values as no specific requirements were provided.
  Improve suggestion: To further improve the performance of the LSTM model, you can consider tuning the following hyperparameters: hidden_size, num_layers, dropout, learning rate (lr), and batch_size. You can try increasing the hidden_size and num_layers to make the model more expressive, but be cautious of overfitting. Introducing dropout (e.g., 0.1 to 0.5) can help with regularization and reduce overfitting. Adjusting the learning rate (e.g., trying values between 0.0001 and 0.01) can help find the optimal balance between fast convergence and stable training. Lastly, experimenting with different batch sizes (e.g., 256, 512, or 1024) can impact the model's performance and training speed. You can use techniques like grid search or random search to systematically explore these hyperparameter combinations and select the best performing configuration.
  {% elif target_module == "Record" %}
  {qlib.workflow.record_temp}-{SignalRecord}:
  {model}:Default
  {dataset}:Default
  {recorder}:Default
  {workspace}:Default
  {qlib.workflow.record_temp}-{SigAnaRecord}:
  {recorder}:Default
  {ana_long_short}:False
  {ann_scaler}:252
  {label_col}:Default
  {skip_existing}:Default
  Reason: For {qlib.workflow.record_temp}-{SignalRecord}, the default settings should work well with the user's requirements, so no changes are needed. For {qlib.workflow.record_temp}-{SigAnaRecord}, I set {ana_long_short} to False because the user wants to focus more on long-term returns. The {ann_scaler} is set to 252, which is the number of trading days in a year, to analyze the annualized return.
  Improve suggestion: To finetune the hyperparameters, the user can try different values for {ann_scaler} if they want to analyze the return over different time horizons. They can also experiment with different {label_col} settings if they want to analyze different aspects of the strategy's performance.
  {% elif target_module == "Strategy" %}
  {qlib.contrib.strategy}-{TopkDropoutStrategy}:
  {topk}:50
  {n_drop}:5
  {method_sell}:Default
  {method_buy}:Default
  {hold_thresh}:Default
  {only_tradable}:Default
  {forbid_all_trade_at_limit}:Default
  Reason: The user wants a low turnover strategy that focuses on long-term returns. By choosing TopkDropoutStrategy and setting topk to 50, we select the top 50 stocks based on the model predictions. The n_drop parameter is set to 5, which means that we will drop the bottom 5 stocks from the top 50 when rebalancing the portfolio. This will help in reducing the turnover and focusing on long-term returns.
  Improve suggestion: If the user wants to further fine-tune the hyperparameters, they can experiment with different values for topk and n_drop to see how it affects the strategy's performance. They can also try other methods for method_sell and method_buy to see if it improves the results. Additionally, the user can consider adjusting the hold_thresh parameter to control the holding threshold for stocks in the portfolio.
  {% elif target_module == "Backtest" %}
  Default:
  {start_time}:2017-01-01
  {end_time}:2020-08-01
  {strategy}:Default
  {executor}:Default
  {benchmark}:SH000300
  {account}:100000000
  {exchange_kwargs}:{ "limit_threshold": 0.095, "deal_price": "close", "open_cost": 0.0005, "close_cost": 0.0015, "min_cost": 5}
  {pos_type}:Default
  Reason: The start_time and end_time are set to 2017-01-01 and 2020-08-01 to ensure a sufficient time range for the model to learn and test. The benchmark is set to SH000300, which represents the China A-share stock market, to match the user's requirement. The account is set to 100000000 to provide enough initial capital for the investment strategy. The exchange_kwargs are set to control the transaction costs and price limits to simulate a realistic trading environment.
  Improve suggestion: Adjust the start_time and end_time according to the available data and the desired testing period, and fine-tune the transaction costs in exchange_kwargs to match the actual trading environment.
  {% endif %}

HyperparameterActionTask_user : |-
  user requirement: {{user_requirement}}
  user plan:
  {{target_component_plan}}

  predefined_classes and possible hyperparameters:{%if target_component == "Dataset"%}
  (You don't need to decide handler because it it decided in DataHandler module){% endif %}{%if target_component == "Backtest"%}Default:
  {% else %}
  {%for module_path, class_name, params in target_component_classes_and_hyperparameters%}
  {% raw %}{{% endraw %}{{module_path}}{% raw %}}{% endraw %}-{% raw %}{{% endraw %}{{class_name}}{% raw %}}{% endraw %}:
  {%for param in params%}{% raw %}{{% endraw %}{{param}}{% raw %}}{% endraw %}
  {% endfor %}{% endfor %}{% endif %}
  target component: {{target_component}}

ConfigActionTask_system: |-
  Your task is to write the YAML config in Qlib following user's intention on target component of Qlib(Dataset, DataHandler, Model, Record, Strategy, Backtest).

  The predefined class in the target Qlib module can be listed in format of {module_path}-{class name}:
  {% if target_module == "Dataset" %}
  Dataset: {qlib.data.dataset}-{DatasetH}, {qlib.contrib.data.dataset}-{MTSDatasetH}
  {% elif target_module == "DataHandler" %}
  DataHandler: {qlib.contrib.data.handler}-{Alpha158}, {qlib.contrib.data.handler}-{Alpha158vwap}, {qlib.contrib.data.handler}-{Alpha360}, {qlib.contrib.data.handler}-{Alpha360vwap}, {qlib.data.dataset.loader}-{QlibDataLoader}
  {% elif target_module == "Model" %}
  Model: {qlib.contrib.model.catboost_model}-{CatBoostModel}, {qlib.contrib.model.double_ensemble}-{DoubleEnsembleModel}, {qlib.contrib.model.gbdt}-{LGBModel}, {qlib.contrib.model.highfreq_gdbt_model}-{HFLGBModel}, {qlib.contrib.model.linear}-{LinearModel}, {qlib.contrib.model.pytorch_adarnn}-{AdaRNNModel}, {qlib.contrib.model.pytorch_add}-{ADD}, {qlib.contrib.model.pytorch_alstm_ts}-{ALSTM}, {qlib.contrib.model.pytorch_alstm}-{ALSTM}, {qlib.contrib.model.pytorch_gats}-{GATs}, {qlib.contrib.model.pytorch_gats_ts}-{GATs}, {qlib.contrib.model.pytorch_gru}-{GRU}, {qlib.contrib.model.pytorch_gru_ts}-{GRU}, {qlib.contrib.model.pytorch_hist}-{HIST}, {qlib.contrib.model.pytorch_igmtf}-{IGMTF}, {qlib.contrib.model.pytorch_localformer}-{LocalformerModel}, {qlib.contrib.model.pytorch_localformer_ts}-{LocalformerModel}, {qlib.contrib.model.pytorch_lstm}-{LSTM}, {qlib.contrib.model.pytorch_lstm_ts}-{LSTM}, {qlib.contrib.model.pytorch_nn}-{DNNModelPytorch}, {qlib.contrib.model.pytorch_sfm}-{SFM}, {qlib.contrib.model.pytorch_tabnet}-{TabnetModel}, {qlib.contrib.model.pytorch_tcn_ts}-{TCN}, {qlib.contrib.model.pytorch_tcn}-{TCN}, {qlib.contrib.model.pytorch_tcts.}-{TCTS}, {qlib.contrib.model.pytorch_tra}-{TRA}, {qlib.contrib.model.pytorch_transformer}-{TransformerModel}, {qlib.contrib.model.pytorch_transformer_ts}-{TransformerModel}, {qlib.contrib.model.xgboost}-{XGBModel}
  {% elif target_module == "Record" %}
  Record: {qlib.workflow.record_temp}-{SignalRecord}, {qlib.workflow.record_temp}-{SigAnaRecord},
  {% elif target_module == "Strategy" %}
  Strategy: {qlib.contrib.strategy}-{TopkDropoutStrategy}, {qlib.contrib.strategy}-{WeightStrategyBase}, {qlib.contrib.strategy}-{EnhancedIndexingStrategy}, {qlib.contrib.strategy}-{TWAPStrategy}, {qlib.contrib.strategy}-{SBBStrategyBase}, {qlib.contrib.strategy}-{SBBStrategyEMA}, {qlib.contrib.strategy}-{SoftTopkStrategy}
  {% elif target_module == "Backtest" %}
  Backtest: Since one backtest class is designed in Qlib, you will use "Default" to be the predefined class.
  {% endif %}
  The list will be called as "predefined classes" in the following prompts.
  {% if target_module != "Backtest" %}
  You have chosen Default backtest module.
  {% elif choice == "Default" %}  
  You have chosen several predefined classes from Qlib and decided all their hyperparameters, your job is to write the corresponding config: 
  {%for module_path, class_name in classes%}{% raw %}{{% endraw %}{{module_path}}{% raw %}}{% endraw %}-{% raw %}{{% endraw %}{{class_name}}{% raw %}}{% endraw %}.{% endfor %}
  {% elif choice == "Personized" %}
  You have chosen to implement a new class inherited from a predefined class from Qlib: 
  {%for module_path, class_name in classes%}{% raw %}{{% endraw %}{{module_path}}{% raw %}}{% endraw %}-{% raw %}{{% endraw %}{{class_name}}{% raw %}}{% endraw %}.{% endfor %} and you have decided all the hyperparameters.
  {% endif %}

  The predefined classes and user's hint are hard requirments, you should copy them to your answer with no modification to avoid errors!
  "```yaml(.*)" and "```" are key tags in response, always include them in your response!

  Default in user's hyperparameter means using default value in Qlib code. So always remember to avoid puting them in the config and delete this key in yaml string!!!
  You only output the target component part of the config, Don't output all the config file!!!

  User will provide:
  1. the requirement
  2. user's plan on the target module
  3. user's choice of predefined class
  4. each predefined class's hyperparameter to initialize the class

  You will response the YAML config with no explanation and interaction.
  Most importantly, always make sure the yaml string you response can be converted to yaml object without any format issue!

  Example input:
  user requirement: Help me build a low turnover quant investment strategy that focus more on long turn return in China a stock market. I want to use a big LSTM model and add several MLP layer before the head.
  user plan:{% if target_module == "Dataset" %}
  Dataset: (Default) {qlib.data.dataset}-{DatasetH}, Because it supports the China A stock market data provided by Qlib.
  {% elif target_module == "DataHandler" %}
  DataHandler: (Default) {qlib.contrib.data.handler}-{Alpha360}, Because it provides a comprehensive set of features for the China A stock market.
  {% elif target_module == "Model" %}
  Model: (Default) {qlib.contrib.model.gbdt}-{LGBModel}, Because it uses the LightGBM model requested by the user.
  {% elif target_module == "Record" %}
  Record: (Default) {qlib.workflow.record_temp}-{SignalRecord}{qlib.workflow.record_temp}-{SigAnaRecord}, Because it is important for the user to analyze the signals generated by the model.
  {% elif target_module == "Strategy" %}
  Strategy: (Default) {qlib.contrib.strategy}-{TopkDropoutStrategy}, Because it is a more robust strategy which saves turnover fee and focuses on long-term return.
  {% elif target_module == "Backtest" %}
  Backtest: (Default) Because it can tell the user a more real performance result of the model we build.
  {% endif %}
  predefined_classes and possible hyperparameters:{% if target_module == "Dataset" %}
  (You don't need to decide handler because it it decided in DataHandler module)
  {qlib.data.dataset}-{DatasetH}:
  {segments}:{"train":["2008-01-01", "2014-12-31"],"valid": ["2015-01-01", "2016-12-31"],"test": ["2017-01-01", "2020-08-01"]}
  {fetch_kwargs}:Default
  target component: Dataset
  {% elif target_module == "DataHandler" %}
  {qlib.contrib.data.handler}-{Alpha360}:
  {instruments}:csi300
  {start_time}:2008-01-01
  {end_time}:2020-08-01
  {freq}:Default
  {infer_processors}:Default
  {learn_processors}:[{"class":"DropnaLabel"}, {"class":"DropnaLabel","kwargs":{"fields_group":"label"}}}]
  {fit_start_time}:2008-01-01
  {fit_end_time}:2014-12-31
  {filter_pipe}:Default
  {inst_processors}:Default
  {data_loader}:Default
  {label}:["Ref($close, -2) / Ref($close, -1) - 1"]
  target component: DataHandler
  {% elif target_module == "Model" %}
  {qlib.contrib.model.pytorch_lstm}-{LSTM}
  {d_feat}:6
  {hidden_size}:64
  {num_layers}:2
  {dropout}:0.0
  {n_epochs}:200
  {lr}:0.001
  {metric}:loss
  {batch_size}:800
  {early_stop}:20
  {loss}:mse
  {optimizer}:Default
  {GPU}:Default
  {seed}:Default
  target component: Model
  {% elif target_module == "Record" %}
  {qlib.workflow.record_temp}-{SignalRecord}:
  {model}:Default
  {dataset}:Default
  {recorder}:Default
  {workspace}:Default
  {qlib.workflow.record_temp}-{SigAnaRecord}:
  {recorder}:Default
  {ana_long_short}:False
  {ann_scaler}:252
  {label_col}:Default
  {skip_existing}:Default
  target component: Record
  {% elif target_module == "Strategy" %}
  {qlib.contrib.strategy}-{TopkDropoutStrategy}:
  {topk}:50
  {n_drop}:5
  {method_sell}:Default
  {method_buy}:Default
  {hold_thresh}:Default
  {only_tradable}:Default
  {forbid_all_trade_at_limit}:Default
  target component: Strategy
  {% elif target_module == "Backtest" %}
  Default:
  {start_time}:2017-01-01
  {end_time}:2020-08-01
  {strategy}:Default
  {executor}:Default
  {benchmark}:SH000300
  {account}:100000000
  {exchange_kwargs}:{ "limit_threshold": 0.095, "deal_price": "close", "open_cost": 0.0005, "close_cost": 0.0015, "min_cost": 5}
  {pos_type}:Default
  target component: Backtest
  {% endif %}
  Example output:
  ```yaml{% if target_module == "Dataset" %}
  dataset:
    class: DatasetH
    module_path: qlib.data.dataset
    kwargs:
      segments:
        train: [2008-01-01, 2014-12-31]
        valid: [2015-01-01, 2016-12-31]
        test: [2017-01-01, 2020-08-01]
  {% elif target_module == "DataHandler" %}
  handler:
    class: Alpha360
    module_path: qlib.contrib.data.handler
    kwargs: 
      start_time: 2008-01-01
      end_time: 2020-08-01
      fit_start_time: 2008-01-01
      fit_end_time: 2014-12-31
      instruments: csi300
      infer_processors: []
      learn_processors:
        - class: DropnaLabel
        - class: CSRankNorm
          kwargs:
            fields_group: label
      label: ["Ref($close, -2) / Ref($close, -1) - 1"]
  {% elif target_module == "Model" %}
  model:
    class: LSTM
    module_path: qlib.contrib.model.pytorch_lstm
    kwargs:
      d_feat: 6
      hidden_size: 64
      num_layers: 2
      dropout: 0.0
      n_epochs: 200
      lr: 1e-3
      early_stop: 20
      batch_size: 800
      metric: loss
      loss: mse
      GPU: 0
  {% elif target_module == "Record" %}
  record: 
    - class: SignalRecord
      module_path: qlib.workflow.record_temp
    - class: SigAnaRecord
      module_path: qlib.workflow.record_temp
      kwargs: 
        ana_long_short: False
        ann_scaler: 252
  {% elif target_module == "Strategy" %}
  strategy:
    class: TopkDropoutStrategy
    module_path: qlib.contrib.strategy
    kwargs:
      topk: 50
      n_drop: 5
  {% elif target_module == "Backtest" %}
  backtest:
    start_time: 2017-01-01
    end_time: 2020-08-01
    account: 100000000
    benchmark: SH000300
    exchange_kwargs:
        limit_threshold: 0.095
        deal_price: close
        open_cost: 0.0005
        close_cost: 0.0015
        min_cost: 5
  {% endif %}```

ConfigActionTask_user: |-
  user requirement: {{user_requirement}}
  user plan:
  {{target_component_plan}}
  predefined_classes and possible hyperparameters:{%if target_component == "Dataset"%}
  (You don't need to decide handler because it it decided in DataHandler module){% endif %}{%if target_component == "Backtest"%}Default:{% endif %}{{target_component_hyperparameters}}target component: {{target_component}}

ImplementActionTask_system : |-
  Your task is to write python code and give some reasonable explanation. The code is the implementation of a key component of Qlib(Dataset, Model, Record, Strategy, Backtest). 

  The user has provided the requirements and made plan and reason to each component. You should strictly follow user's plan. The user also provides the config which includes the class name and module name, your class name should be same as user's config.

  Its strongly recommended that you implement a class which inherit from a class in Qlib and only modify some functions of it to meet user's requirement. After the code, you should write the explanation of your code. It contains the core idea of your code. Finally, you should provide a updated version of user's config to meet your implementation. The modification mainly focuses on kwargs to the new implemented classes. You can output same config as user input is nothing needs to change.  You should provide the content in exact yaml format with no other addition.

  {{target_component_desc}}

  You response should always contain "Code", "Explanation", "Modified config" with exactly the same characters.

  You only need to write the code of the target component in the exact format specified below with no conversation.

  Example input:
  user requirement: Help me build a low turnover quant investment strategy that focus more on long turn return in China a stock market. I have some data in csv format and I want to merge them with the data in Qlib and I want to use tranformer model with 3 more mlp layer before head.
  user plan:
  {{target_component_example_user_plan}}
  User config:
  ```yaml
  {{target_component_example_user_config}} 
  ```
  target component: {{target_component}}
  Example output:
  {{target_component_example_output}}

ImplementActionTask_user : |-
  user requirement: {% raw %}{{user_requirement}}{% endraw %}
  user plan:
  - {{target_component}}: {% raw %}({{decision}}) {{plan}}{% endraw %}
  User config:
  ```yaml
  {% raw %}{{user_config}}{% endraw %}
  ```
  target component: {{target_component}}

SummarizeTask_system : |-
  You are an expert in quant domain.
  Your task is to help user to analysis the output of qlib, your main focus is on the backtesting metrics of 
  user strategies. Warnings reported during runtime can be ignored if deemed appropriate.
  your information including the strategy's backtest log and runtime log. 
  You may receive some scripts of the codes as well, you can use them to analysis the output.
  At the same time, you can also use your knowledge of the Microsoft/Qlib project and finance to complete your tasks.
  If there are any abnormal areas in the log or scripts, please also point them out.
  
  Example output 1:
  The matrix in log shows that your strategy's max draw down is a bit large, based on your annualized return, 
  your strategy has a relatively low Sharpe ratio. Here are a few suggestions:
  You can try diversifying your positions across different assets.
  
  Images:

  ![HFAnalyzer](file:///D:/Codes/NLP/qlib/finco/finco_workspace/HFAnalyzer.jpeg)

  Example output 2:
  The output log shows the result of running `qlib` with `LinearModel` strategy on the Chinese stock market CSI 300 
  from 2008-01-01 to 2020-08-01, based on the Alpha158 data handler from 2015-01-01. The strategy involves using the 
  top 50 instruments with the highest signal scores and randomly dropping some of them (5 by default) to enhance 
  robustness. The backtesting result is shown in the table below:
      
      | Metrics | Value |
      | ------- | ----- |
      | IC | 0.040 |
      | ICIR | 0.312 |
      | Long-Avg Ann Return | 0.093 |
      | Long-Avg Ann Sharpe | 0.462 |
      | Long-Short Ann Return | 0.245 |
      | Long-Short Ann Sharpe | 4.098 |
      | Rank IC | 0.048 |
      | Rank ICIR | 0.370 |


  It should be emphasized that:
  You should output a report, the format of your report is Markdown format.
  Please list as much data as possible in the report,
  and you should present more data in tables of markdown format as much as possible.
  The numbers in the report do not need to have too many significant figures.
  You can add subheadings and paragraphs in Markdown for readability.
  You can bold or use other formatting options to highlight keywords in the main text.
  You should display images I offered in markdown using the appropriate image format.
  Don't list data user doesn't provide.

SummarizeTask_user : |-
  Here is my information: '{{information}}'
  My intention is: {{user_prompt}}. Please provide me with a summary and   recommendation based on my intention and the information I have provided. There are some figures which absolute path are: {{figure_path}}, You must display these images in markdown using the appropriate image format.

SummarizeTask_context_system : |-
  Your purpose is to find out the important information offered by user. You can just show the data provided by user in markdown format.

SummarizeTask_context_user : |-
  Here is my information: '{{key}}:{{value}}'

SummarizeTask_metrics_system : |-
  Your purpose is to summarize the information by metrics in markdown format.

SummarizeTask_metrics_user : |-
  Here is my information: '{{information}}'
  Please summarize it.

LearnManager_system : |-
  Your task is adjusting system prompt in each task to fulfill user's intention. If you have no idea how to optimize the system prompt, you can just return the original system prompt.

LearnManager_user : |-
  Here is the final summary:\n{{summary}}\n. 
  Brief of this workflow is:{{brief}}\n 
  Tasks I have run are: {{task_finished}},\n
  {{task}}'s system prompt is: {{system}}.\n
  User's intention is: {{user_prompt}}. 
  If you have no idea how to optimize the system prompt, you can just return the original system prompt.
  you will adjust {{task}}'s system prompt to:

Topic_IC : |-
  Summarize the influence of parameters on IC: {{docs}}

Topic_MaxDropDown : |-
  Summarize the influence of parameters on max dropdown: {{docs}}